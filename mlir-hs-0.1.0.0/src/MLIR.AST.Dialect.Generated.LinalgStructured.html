<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><head><link rel="stylesheet" type="text/css" href="style.css" /><script type="text/javascript" src="highlight.js"></script></head><body><pre><span class="hs-pragma">{-# OPTIONS_GHC -Wno-unused-imports #-}</span><span>
</span><span id="line-2"></span><span class="hs-pragma">{-# OPTIONS_HADDOCK hide, prune, not-home #-}</span><span>
</span><span id="line-3"></span><span>
</span><span id="line-4"></span><span class="hs-keyword">module</span><span> </span><span class="hs-identifier">MLIR.AST.Dialect.Generated.LinalgStructured</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-5"></span><span>
</span><span id="line-6"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">Prelude</span></span><span> </span><span class="hs-keyword">hiding</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier">return</span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier">min</span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier">max</span></span><span class="hs-special">)</span><span>
</span><span id="line-7"></span><span class="hs-keyword">import</span><span> </span><span class="hs-keyword">qualified</span><span> </span><span class="annot"><span class="hs-identifier">Data.ByteString</span></span><span> </span><span class="hs-keyword">as</span><span> </span><span class="annot"><span class="hs-identifier">BS</span></span><span>
</span><span id="line-8"></span><span class="hs-keyword">import</span><span> </span><span class="hs-keyword">qualified</span><span> </span><span class="annot"><span class="hs-identifier">Data.Map.Strict</span></span><span> </span><span class="hs-keyword">as</span><span> </span><span class="annot"><span class="hs-identifier">M</span></span><span>
</span><span id="line-9"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">Control.Monad</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier">liftM</span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier">void</span></span><span class="hs-special">)</span><span>
</span><span id="line-10"></span><span>
</span><span id="line-11"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="MLIR.AST.html"><span class="hs-identifier">MLIR.AST</span></a></span><span>
</span><span id="line-12"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="MLIR.AST.Builder.html"><span class="hs-identifier">MLIR.AST.Builder</span></a></span><span>
</span><span id="line-13"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="MLIR.AST.PatternUtil.html"><span class="hs-identifier">MLIR.AST.PatternUtil</span></a></span><span>
</span><span id="line-14"></span><span class="hs-keyword">import</span><span> </span><span class="hs-keyword">qualified</span><span> </span><span class="annot"><a href="MLIR.AST.Dialect.Affine.html"><span class="hs-identifier">MLIR.AST.Dialect.Affine</span></a></span><span> </span><span class="hs-keyword">as</span><span> </span><span class="annot"><span class="hs-identifier">Affine</span></span><span>
</span><span id="line-15"></span><span>
</span><span id="line-16"></span><span class="hs-comment">-- * batch_matmul_i16_i16_i32</span><span>
</span><span id="line-17"></span><span class="hs-comment">-- $batch_matmul_i16_i16_i32</span><span>
</span><span id="line-18"></span><span class="hs-comment">-- </span><span>
</span><span id="line-19"></span><span>
</span><span id="line-20"></span><span class="hs-comment">-- * batch_matmul_i32_i32_i32</span><span>
</span><span id="line-21"></span><span class="hs-comment">-- $batch_matmul_i32_i32_i32</span><span>
</span><span id="line-22"></span><span class="hs-comment">-- </span><span>
</span><span id="line-23"></span><span>
</span><span id="line-24"></span><span class="hs-comment">-- * batch_matmul_i8_i8_i32</span><span>
</span><span id="line-25"></span><span class="hs-comment">-- $batch_matmul_i8_i8_i32</span><span>
</span><span id="line-26"></span><span class="hs-comment">-- </span><span>
</span><span id="line-27"></span><span>
</span><span id="line-28"></span><span class="hs-comment">-- * batch_matmul</span><span>
</span><span id="line-29"></span><span class="hs-comment">-- $batch_matmul</span><span>
</span><span id="line-30"></span><span class="hs-comment">-- </span><span>
</span><span id="line-31"></span><span class="hs-comment">-- Numeric casting is performed on the operands to the inner multiply, promoting</span><span>
</span><span id="line-32"></span><span class="hs-comment">-- them to the same data type as the accumulator/output.</span><span>
</span><span id="line-33"></span><span class="hs-comment">--       </span><span>
</span><span id="line-34"></span><span>
</span><span id="line-35"></span><span class="hs-comment">-- * conv_3d</span><span>
</span><span id="line-36"></span><span class="hs-comment">-- $conv_3d</span><span>
</span><span id="line-37"></span><span class="hs-comment">-- </span><span>
</span><span id="line-38"></span><span>
</span><span id="line-39"></span><span class="hs-comment">-- * conv_2d</span><span>
</span><span id="line-40"></span><span class="hs-comment">-- $conv_2d</span><span>
</span><span id="line-41"></span><span class="hs-comment">-- </span><span>
</span><span id="line-42"></span><span>
</span><span id="line-43"></span><span class="hs-comment">-- * conv_3d_input_ncdhw_filter_dhwcf</span><span>
</span><span id="line-44"></span><span class="hs-comment">-- $conv_3d_input_ncdhw_filter_dhwcf</span><span>
</span><span id="line-45"></span><span class="hs-comment">-- </span><span>
</span><span id="line-46"></span><span class="hs-comment">-- Computes a 3-D convolution given 5-D input and filter. The data layout</span><span>
</span><span id="line-47"></span><span class="hs-comment">-- of input is NCDHW and the data layout of filter is DHWCF.</span><span>
</span><span id="line-48"></span><span class="hs-comment">-- </span><span>
</span><span id="line-49"></span><span class="hs-comment">-- The indexing maps for these three tensors contain 9 dimensions, following the</span><span>
</span><span id="line-50"></span><span class="hs-comment">-- order of (@N@, @F@, @D@, @H@, @W@, @KD@, @KH@, @KW@, @C@).</span><span>
</span><span id="line-51"></span><span class="hs-comment">--       </span><span>
</span><span id="line-52"></span><span>
</span><span id="line-53"></span><span class="hs-comment">-- * conv_2d_input_nchw_filter_hwcf</span><span>
</span><span id="line-54"></span><span class="hs-comment">-- $conv_2d_input_nchw_filter_hwcf</span><span>
</span><span id="line-55"></span><span class="hs-comment">-- </span><span>
</span><span id="line-56"></span><span class="hs-comment">-- Computes a 2-D convolution given 4-D input and filter. The data layout</span><span>
</span><span id="line-57"></span><span class="hs-comment">-- of input is NCHW and the data layout of filter is HWCF.</span><span>
</span><span id="line-58"></span><span class="hs-comment">-- </span><span>
</span><span id="line-59"></span><span class="hs-comment">-- The indexing maps for these three tensors contain 7 dimensions, following the</span><span>
</span><span id="line-60"></span><span class="hs-comment">-- order of (@N@, @F@, @H@, @W@, @KH@, @KW@, @C@).</span><span>
</span><span id="line-61"></span><span class="hs-comment">--       </span><span>
</span><span id="line-62"></span><span>
</span><span id="line-63"></span><span class="hs-comment">-- * conv_1d_input_ncw_filter_wcf</span><span>
</span><span id="line-64"></span><span class="hs-comment">-- $conv_1d_input_ncw_filter_wcf</span><span>
</span><span id="line-65"></span><span class="hs-comment">-- </span><span>
</span><span id="line-66"></span><span class="hs-comment">-- Computes a 1-D convolution given 3-D input and filter. The data layout</span><span>
</span><span id="line-67"></span><span class="hs-comment">-- of input is NCW and the data layout of filter is WCF.</span><span>
</span><span id="line-68"></span><span class="hs-comment">-- </span><span>
</span><span id="line-69"></span><span class="hs-comment">-- The indexing maps for these three tensors contain 5 dimensions, following the</span><span>
</span><span id="line-70"></span><span class="hs-comment">-- order of (@N@, @F@, @W@, @KW@, @C@).</span><span>
</span><span id="line-71"></span><span class="hs-comment">--       </span><span>
</span><span id="line-72"></span><span>
</span><span id="line-73"></span><span class="hs-comment">-- * conv_3d_input_ndhwc_filter_dhwcf</span><span>
</span><span id="line-74"></span><span class="hs-comment">-- $conv_3d_input_ndhwc_filter_dhwcf</span><span>
</span><span id="line-75"></span><span class="hs-comment">-- </span><span>
</span><span id="line-76"></span><span class="hs-comment">-- Computes a 3-D convolution given 5-D input and filter. The data layout</span><span>
</span><span id="line-77"></span><span class="hs-comment">-- of input is NDHWC and the data layout of filter is DHWCF.</span><span>
</span><span id="line-78"></span><span class="hs-comment">-- </span><span>
</span><span id="line-79"></span><span class="hs-comment">-- The indexing maps for these three tensors contain 9 dimensions, following the</span><span>
</span><span id="line-80"></span><span class="hs-comment">-- order of (@N@, @D@, @H@, @W@, @F@, @KD@, @KH@, @KW@, @C@).</span><span>
</span><span id="line-81"></span><span class="hs-comment">--       </span><span>
</span><span id="line-82"></span><span>
</span><span id="line-83"></span><span class="hs-comment">-- * conv_2d_input_nhwc_filter_hwcf</span><span>
</span><span id="line-84"></span><span class="hs-comment">-- $conv_2d_input_nhwc_filter_hwcf</span><span>
</span><span id="line-85"></span><span class="hs-comment">-- </span><span>
</span><span id="line-86"></span><span class="hs-comment">-- Computes a 2-D convolution given 4-D input and filter. The data layout</span><span>
</span><span id="line-87"></span><span class="hs-comment">-- of input is NHWC and the data layout of filter is HWCF.</span><span>
</span><span id="line-88"></span><span class="hs-comment">-- </span><span>
</span><span id="line-89"></span><span class="hs-comment">-- The indexing maps for these three tensors contain 7 dimensions, following the</span><span>
</span><span id="line-90"></span><span class="hs-comment">-- order of (@N@, @H@, @W@, @F@, @KH@, @KW@, @C@).</span><span>
</span><span id="line-91"></span><span class="hs-comment">--       </span><span>
</span><span id="line-92"></span><span>
</span><span id="line-93"></span><span class="hs-comment">-- * conv_1d_input_nwc_filter_wcf</span><span>
</span><span id="line-94"></span><span class="hs-comment">-- $conv_1d_input_nwc_filter_wcf</span><span>
</span><span id="line-95"></span><span class="hs-comment">-- </span><span>
</span><span id="line-96"></span><span class="hs-comment">-- Computes a 1-D convolution given 3-D input and filter. The data layout</span><span>
</span><span id="line-97"></span><span class="hs-comment">-- of input is NWC and the data layout of filter is WCF.</span><span>
</span><span id="line-98"></span><span class="hs-comment">-- </span><span>
</span><span id="line-99"></span><span class="hs-comment">-- The indexing maps for these three tensors contain 5 dimensions, following the</span><span>
</span><span id="line-100"></span><span class="hs-comment">-- order of (@N@, @W@, @F@, @KW@, @C@).</span><span>
</span><span id="line-101"></span><span class="hs-comment">--       </span><span>
</span><span id="line-102"></span><span>
</span><span id="line-103"></span><span class="hs-comment">-- * conv_3d_ncdhw</span><span>
</span><span id="line-104"></span><span class="hs-comment">-- $conv_3d_ncdhw</span><span>
</span><span id="line-105"></span><span class="hs-comment">-- </span><span>
</span><span id="line-106"></span><span>
</span><span id="line-107"></span><span class="hs-comment">-- * conv_2d_nchw</span><span>
</span><span id="line-108"></span><span class="hs-comment">-- $conv_2d_nchw</span><span>
</span><span id="line-109"></span><span class="hs-comment">-- </span><span>
</span><span id="line-110"></span><span>
</span><span id="line-111"></span><span class="hs-comment">-- * conv_1d_ncw</span><span>
</span><span id="line-112"></span><span class="hs-comment">-- $conv_1d_ncw</span><span>
</span><span id="line-113"></span><span class="hs-comment">-- </span><span>
</span><span id="line-114"></span><span>
</span><span id="line-115"></span><span class="hs-comment">-- * conv_3d_ndhwc</span><span>
</span><span id="line-116"></span><span class="hs-comment">-- $conv_3d_ndhwc</span><span>
</span><span id="line-117"></span><span class="hs-comment">-- </span><span>
</span><span id="line-118"></span><span>
</span><span id="line-119"></span><span class="hs-comment">-- * conv_2d_nhwc</span><span>
</span><span id="line-120"></span><span class="hs-comment">-- $conv_2d_nhwc</span><span>
</span><span id="line-121"></span><span class="hs-comment">-- </span><span>
</span><span id="line-122"></span><span>
</span><span id="line-123"></span><span class="hs-comment">-- * conv_1d_nwc</span><span>
</span><span id="line-124"></span><span class="hs-comment">-- $conv_1d_nwc</span><span>
</span><span id="line-125"></span><span class="hs-comment">-- </span><span>
</span><span id="line-126"></span><span>
</span><span id="line-127"></span><span class="hs-comment">-- * conv</span><span>
</span><span id="line-128"></span><span class="hs-comment">-- $conv</span><span>
</span><span id="line-129"></span><span class="hs-comment">-- </span><span>
</span><span id="line-130"></span><span class="hs-comment">-- Generic n-D convolution as described in the TF documentation:</span><span>
</span><span id="line-131"></span><span class="hs-comment">-- https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/nn/convolution</span><span>
</span><span id="line-132"></span><span class="hs-comment">-- </span><span>
</span><span id="line-133"></span><span class="hs-comment">-- @</span><span>
</span><span id="line-134"></span><span class="hs-comment">--   output[b, x[0], ..., x[N-1], k] =</span><span>
</span><span id="line-135"></span><span class="hs-comment">--   sum_{z[0], ..., z[N-1], q}</span><span>
</span><span id="line-136"></span><span class="hs-comment">--       filter[z[0], ..., z[N-1], q, k] *</span><span>
</span><span id="line-137"></span><span class="hs-comment">--       padded_input[b,</span><span>
</span><span id="line-138"></span><span class="hs-comment">--                    x[0] * strides[0] + dilation_rate[0] * z[0],</span><span>
</span><span id="line-139"></span><span class="hs-comment">--                    ...,</span><span>
</span><span id="line-140"></span><span class="hs-comment">--                    x[N-1] * strides[N-1] + dilation_rate[N-1] * z[N-1],</span><span>
</span><span id="line-141"></span><span class="hs-comment">--                    q]</span><span>
</span><span id="line-142"></span><span class="hs-comment">-- @</span><span>
</span><span id="line-143"></span><span class="hs-comment">--   </span><span>
</span><span id="line-144"></span><span>
</span><span id="line-145"></span><span class="hs-comment">-- * conv_1d</span><span>
</span><span id="line-146"></span><span class="hs-comment">-- $conv_1d</span><span>
</span><span id="line-147"></span><span class="hs-comment">-- </span><span>
</span><span id="line-148"></span><span>
</span><span id="line-149"></span><span class="hs-comment">-- * copy</span><span>
</span><span id="line-150"></span><span class="hs-comment">-- $copy</span><span>
</span><span id="line-151"></span><span class="hs-comment">-- </span><span>
</span><span id="line-152"></span><span class="hs-comment">-- Copies the data in the input view into the output view.</span><span>
</span><span id="line-153"></span><span class="hs-comment">-- </span><span>
</span><span id="line-154"></span><span class="hs-comment">-- Usage:</span><span>
</span><span id="line-155"></span><span class="hs-comment">-- </span><span>
</span><span id="line-156"></span><span class="hs-comment">-- @</span><span>
</span><span id="line-157"></span><span class="hs-comment">-- linalg.copy(%arg0, %arg1) : memref\&lt;?xf32, stride_specification&gt;,</span><span>
</span><span id="line-158"></span><span class="hs-comment">--                             memref\&lt;?xf32, stride_specification&gt;</span><span>
</span><span id="line-159"></span><span class="hs-comment">-- @</span><span>
</span><span id="line-160"></span><span class="hs-comment">-- </span><span>
</span><span id="line-161"></span><span class="hs-comment">-- One possible lowering to loop form is:</span><span>
</span><span id="line-162"></span><span class="hs-comment">-- </span><span>
</span><span id="line-163"></span><span class="hs-comment">-- @</span><span>
</span><span id="line-164"></span><span class="hs-comment">-- %0 = linalg.dim %arg0, 0 : index</span><span>
</span><span id="line-165"></span><span class="hs-comment">-- scf.for %i0 = %c0 to %0 step %c1 {</span><span>
</span><span id="line-166"></span><span class="hs-comment">--   %1 = load %arg0[%i0] : memref\&lt;?xf32, stride_specification&gt;</span><span>
</span><span id="line-167"></span><span class="hs-comment">--   store %1, %arg1[%i0] : memref\&lt;?xf32, stride_specification&gt;</span><span>
</span><span id="line-168"></span><span class="hs-comment">-- }</span><span>
</span><span id="line-169"></span><span class="hs-comment">-- @</span><span>
</span><span id="line-170"></span><span class="hs-comment">-- </span><span>
</span><span id="line-171"></span><span class="hs-comment">-- Optionally, can take @input_permutation@ and @output_permutation@ attributes</span><span>
</span><span id="line-172"></span><span class="hs-comment">-- to reorder the dimensions of the input and output views.</span><span>
</span><span id="line-173"></span><span class="hs-comment">-- </span><span>
</span><span id="line-174"></span><span class="hs-comment">-- Usage:</span><span>
</span><span id="line-175"></span><span class="hs-comment">-- </span><span>
</span><span id="line-176"></span><span class="hs-comment">-- @</span><span>
</span><span id="line-177"></span><span class="hs-comment">-- linalg.copy(%arg0, %arg1) {inputPermutation : (i, j, k) -&gt; (i, k, j),</span><span>
</span><span id="line-178"></span><span class="hs-comment">--                            outputPermutation : (i, j, k) -&gt; (k, j, i)} :</span><span>
</span><span id="line-179"></span><span class="hs-comment">--   memref\&lt;?x?x?xf32, stride_specification&gt;,</span><span>
</span><span id="line-180"></span><span class="hs-comment">--   memref\&lt;?x?x?xf32, stride_specification&gt;</span><span>
</span><span id="line-181"></span><span class="hs-comment">-- @</span><span>
</span><span id="line-182"></span><span class="hs-comment">-- </span><span>
</span><span id="line-183"></span><span class="hs-comment">-- One possible lowering to loop form is:</span><span>
</span><span id="line-184"></span><span class="hs-comment">-- </span><span>
</span><span id="line-185"></span><span class="hs-comment">-- @</span><span>
</span><span id="line-186"></span><span class="hs-comment">-- %0 = linalg.dim %arg0, 0</span><span>
</span><span id="line-187"></span><span class="hs-comment">-- %1 = linalg.dim %arg0, 1</span><span>
</span><span id="line-188"></span><span class="hs-comment">-- %2 = linalg.dim %arg0, 2</span><span>
</span><span id="line-189"></span><span class="hs-comment">-- scf.for %i0 = %c0 to %{{.*}} step %c1 {</span><span>
</span><span id="line-190"></span><span class="hs-comment">--   scf.for %i1 = %c0 to %{{.*}} step %c1 {</span><span>
</span><span id="line-191"></span><span class="hs-comment">--     scf.for %i2 = %c0 to %{{.*}} step %c1 {</span><span>
</span><span id="line-192"></span><span class="hs-comment">--       %3 = load %arg0[%i0, %i2, %i1] :</span><span>
</span><span id="line-193"></span><span class="hs-comment">--               memref\&lt;?x?x?xf32, stride_specification&gt;</span><span>
</span><span id="line-194"></span><span class="hs-comment">--       store %3, %arg1[%i2, %i1, %i0] :</span><span>
</span><span id="line-195"></span><span class="hs-comment">--               memref\&lt;?x?x?xf32, stride_specification&gt;</span><span>
</span><span id="line-196"></span><span class="hs-comment">-- @</span><span>
</span><span id="line-197"></span><span class="hs-comment">-- </span><span>
</span><span id="line-198"></span><span class="hs-comment">-- The views are expected to be compatible for correctness but this is not</span><span>
</span><span id="line-199"></span><span class="hs-comment">-- enforced at the moment.</span><span>
</span><span id="line-200"></span><span class="hs-comment">--   </span><span>
</span><span id="line-201"></span><span>
</span><span id="line-202"></span><span class="hs-keyword">pattern</span><span> </span><span class="annot"><a href="MLIR.AST.Dialect.Generated.LinalgStructured.html#InternalCopyOpAttributes"><span class="hs-identifier hs-type">InternalCopyOpAttributes</span></a></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="MLIR.AST.Dialect.Affine.html#Map"><span class="hs-identifier hs-type">Affine.Map</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="MLIR.AST.Dialect.Affine.html#Map"><span class="hs-identifier hs-type">Affine.Map</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="MLIR.AST.html#NamedAttributes"><span class="hs-identifier hs-type">NamedAttributes</span></a></span><span>
</span><span id="line-203"></span><span class="hs-keyword">pattern</span><span> </span><span id="%24bInternalCopyOpAttributes"><span id="%24mInternalCopyOpAttributes"><span id="InternalCopyOpAttributes"><span class="annot"><span class="annottext">$bInternalCopyOpAttributes :: Map -&gt; Map -&gt; NamedAttributes
$mInternalCopyOpAttributes :: forall r. NamedAttributes -&gt; (Map -&gt; Map -&gt; r) -&gt; (Void# -&gt; r) -&gt; r
</span><a href="MLIR.AST.Dialect.Generated.LinalgStructured.html#%24bInternalCopyOpAttributes"><span class="hs-identifier hs-var hs-var hs-var hs-var">InternalCopyOpAttributes</span></a></span></span></span></span><span> </span><span class="annot"><a href="#local-6989586621679296756"><span class="hs-identifier hs-type">inputPermutation</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679296755"><span class="hs-identifier hs-type">outputPermutation</span></a></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="hs-special">(</span><span class="hs-special">(</span><span class="hs-glyph">\</span><span id="local-6989586621679296754"><span class="annot"><a href="#local-6989586621679296754"><span class="hs-identifier hs-var">m</span></a></span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">M.lookup</span></span><span> </span><span class="annot"><span class="hs-string">&quot;inputPermutation&quot;</span></span><span> </span><span class="annot"><a href="#local-6989586621679296754"><span class="hs-identifier hs-type">m</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">M.lookup</span></span><span> </span><span class="annot"><span class="hs-string">&quot;outputPermutation&quot;</span></span><span> </span><span class="annot"><a href="#local-6989586621679296754"><span class="hs-identifier hs-type">m</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">Just</span></span><span> </span><span class="hs-special">(</span><span class="hs-special">(</span><span class="annot"><a href="MLIR.AST.html#AffineMapAttr"><span class="hs-identifier hs-type">AffineMapAttr</span></a></span><span> </span><span id="local-6989586621679296756"><span class="annot"><a href="#local-6989586621679296756"><span class="hs-identifier hs-var">inputPermutation</span></a></span></span><span class="hs-special">)</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Just</span></span><span> </span><span class="hs-special">(</span><span class="hs-special">(</span><span class="annot"><a href="MLIR.AST.html#AffineMapAttr"><span class="hs-identifier hs-type">AffineMapAttr</span></a></span><span> </span><span id="local-6989586621679296755"><span class="annot"><a href="#local-6989586621679296755"><span class="hs-identifier hs-var">outputPermutation</span></a></span></span><span class="hs-special">)</span><span class="hs-special">)</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-204"></span><span>  </span><span class="hs-keyword">where</span><span> </span><span class="annot"><a href="MLIR.AST.Dialect.Generated.LinalgStructured.html#InternalCopyOpAttributes"><span class="hs-identifier hs-var">InternalCopyOpAttributes</span></a></span><span> </span><span id="local-6989586621679296751"><span class="annot"><span class="annottext">Map
</span><a href="#local-6989586621679296751"><span class="hs-identifier hs-var">inputPermutation</span></a></span></span><span> </span><span id="local-6989586621679296750"><span class="annot"><span class="annottext">Map
</span><a href="#local-6989586621679296750"><span class="hs-identifier hs-var">outputPermutation</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">[(Name, Attribute)] -&gt; NamedAttributes
forall k a. Ord k =&gt; [(k, a)] -&gt; Map k a
</span><span class="hs-identifier hs-var">M.fromList</span></span><span> </span><span class="hs-special">[</span><span class="hs-special">(</span><span class="annot"><span class="annottext">Name
</span><span class="hs-string">&quot;inputPermutation&quot;</span></span><span class="hs-special">,</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Map -&gt; Attribute
</span><a href="MLIR.AST.html#AffineMapAttr"><span class="hs-identifier hs-var">AffineMapAttr</span></a></span><span> </span><span class="annot"><span class="annottext">Map
</span><a href="#local-6989586621679296751"><span class="hs-identifier hs-var">inputPermutation</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Name
</span><span class="hs-string">&quot;outputPermutation&quot;</span></span><span class="hs-special">,</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Map -&gt; Attribute
</span><a href="MLIR.AST.html#AffineMapAttr"><span class="hs-identifier hs-var">AffineMapAttr</span></a></span><span> </span><span class="annot"><span class="annottext">Map
</span><a href="#local-6989586621679296750"><span class="hs-identifier hs-var">outputPermutation</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span class="hs-special">]</span><span>
</span><span id="line-205"></span><span>
</span><span id="line-206"></span><span class="hs-comment">-- * depthwise_conv_2d_input_nhwc_filter_hwcf</span><span>
</span><span id="line-207"></span><span class="hs-comment">-- $depthwise_conv_2d_input_nhwc_filter_hwcf</span><span>
</span><span id="line-208"></span><span class="hs-comment">-- </span><span>
</span><span id="line-209"></span><span class="hs-comment">-- This operation performs depth-wise 2-D convolution over an input @I@ and filter</span><span>
</span><span id="line-210"></span><span class="hs-comment">-- @F@ and generates output @O@ using the following computation:</span><span>
</span><span id="line-211"></span><span class="hs-comment">-- </span><span>
</span><span id="line-212"></span><span class="hs-comment">-- @</span><span>
</span><span id="line-213"></span><span class="hs-comment">--   O(n, oh, ow, ci, co) = AddFOp\&lt;kh, kw&gt;(</span><span>
</span><span id="line-214"></span><span class="hs-comment">--       O(n, oh, ow, ci, co),</span><span>
</span><span id="line-215"></span><span class="hs-comment">--       MulFOp(I(n, oh * strides[0] + kh * dilations[0], ow * strides[1] + kw * dilations[1], ci),</span><span>
</span><span id="line-216"></span><span class="hs-comment">--        K(kh, kw, ci, co)));</span><span>
</span><span id="line-217"></span><span class="hs-comment">-- @</span><span>
</span><span id="line-218"></span><span class="hs-comment">-- </span><span>
</span><span id="line-219"></span><span class="hs-comment">-- where</span><span>
</span><span id="line-220"></span><span class="hs-comment">-- </span><span>
</span><span id="line-221"></span><span class="hs-comment">-- * @I@ is a 4-D tensor with shape @(N, IH, IW, CI)@.</span><span>
</span><span id="line-222"></span><span class="hs-comment">-- * @F@ is a 4-D tensor with shape @(KH, KW, CI, CO)@.</span><span>
</span><span id="line-223"></span><span class="hs-comment">-- * @O@ is a 5-D tensor with shape @(N, OH, OW, CI, CO)@.</span><span>
</span><span id="line-224"></span><span class="hs-comment">-- * @strides@ is a 2-element vector attribute for window strides along the</span><span>
</span><span id="line-225"></span><span class="hs-comment">--   height/width dimension.</span><span>
</span><span id="line-226"></span><span class="hs-comment">-- </span><span>
</span><span id="line-227"></span><span class="hs-comment">-- The indexing maps for these three tensors contain 7 dimensions, following the</span><span>
</span><span id="line-228"></span><span class="hs-comment">-- order of (@N@, @OH@, @OW@, @CI@, @CO@, @KH@, @KW@).</span><span>
</span><span id="line-229"></span><span class="hs-comment">-- </span><span>
</span><span id="line-230"></span><span class="hs-comment">-- Note: this op only supports any channel multiplier, which is @CO@. To map back</span><span>
</span><span id="line-231"></span><span class="hs-comment">-- to 4D result as DepthwiseConvInputNHWCFilterHWCOp, you will have to create a</span><span>
</span><span id="line-232"></span><span class="hs-comment">-- Linalg reshape op which collapses @CI@ and @CO@ into one dimension.</span><span>
</span><span id="line-233"></span><span class="hs-comment">--       </span><span>
</span><span id="line-234"></span><span>
</span><span id="line-235"></span><span class="hs-comment">-- * depthwise_conv_2d_input_nhwc_filter_hwc</span><span>
</span><span id="line-236"></span><span class="hs-comment">-- $depthwise_conv_2d_input_nhwc_filter_hwc</span><span>
</span><span id="line-237"></span><span class="hs-comment">-- </span><span>
</span><span id="line-238"></span><span class="hs-comment">-- This operation performs depth-wise 2-D convolution over an input @I@ and filter</span><span>
</span><span id="line-239"></span><span class="hs-comment">-- @F@ and generates output @O@ using the following computation:</span><span>
</span><span id="line-240"></span><span class="hs-comment">-- </span><span>
</span><span id="line-241"></span><span class="hs-comment">-- @</span><span>
</span><span id="line-242"></span><span class="hs-comment">-- O(n, oh, ow, c) = AddFOp\&lt;kh, kw&gt;(</span><span>
</span><span id="line-243"></span><span class="hs-comment">--     O(n, oh, ow, c),</span><span>
</span><span id="line-244"></span><span class="hs-comment">--     MulFOp(I(n, oh * strides[0] + kh * dilations[0], ow * strides[1] + kw * dilations[1], c),</span><span>
</span><span id="line-245"></span><span class="hs-comment">--      K(kh, kw, c)));</span><span>
</span><span id="line-246"></span><span class="hs-comment">-- @</span><span>
</span><span id="line-247"></span><span class="hs-comment">-- </span><span>
</span><span id="line-248"></span><span class="hs-comment">-- where</span><span>
</span><span id="line-249"></span><span class="hs-comment">-- </span><span>
</span><span id="line-250"></span><span class="hs-comment">-- * @I@ is a 4-D tensor with shape @(N, IH, IW, C)@.</span><span>
</span><span id="line-251"></span><span class="hs-comment">-- * @F@ is a 3-D tensor with shape @(KH, KW, C)@.</span><span>
</span><span id="line-252"></span><span class="hs-comment">-- * @O@ is a 4-D tensor with shape @(N, OH, OW, C)@.</span><span>
</span><span id="line-253"></span><span class="hs-comment">-- * @strides@ is a 2-element vector attribute for window strides along the</span><span>
</span><span id="line-254"></span><span class="hs-comment">--   height/width dimension.</span><span>
</span><span id="line-255"></span><span class="hs-comment">-- </span><span>
</span><span id="line-256"></span><span class="hs-comment">-- The indexing maps for these three tensors contain 6 dimensions, following the</span><span>
</span><span id="line-257"></span><span class="hs-comment">-- order of (@N@, @OH@, @OW@, @C@, @KH@, @KW@).</span><span>
</span><span id="line-258"></span><span class="hs-comment">-- </span><span>
</span><span id="line-259"></span><span class="hs-comment">-- Note: this op only supports channel multiplier == 1.</span><span>
</span><span id="line-260"></span><span class="hs-comment">--       </span><span>
</span><span id="line-261"></span><span>
</span><span id="line-262"></span><span class="hs-comment">-- * dot_i16_i16_i32</span><span>
</span><span id="line-263"></span><span class="hs-comment">-- $dot_i16_i16_i32</span><span>
</span><span id="line-264"></span><span class="hs-comment">-- </span><span>
</span><span id="line-265"></span><span>
</span><span id="line-266"></span><span class="hs-comment">-- * dot_i32_i32_i32</span><span>
</span><span id="line-267"></span><span class="hs-comment">-- $dot_i32_i32_i32</span><span>
</span><span id="line-268"></span><span class="hs-comment">-- </span><span>
</span><span id="line-269"></span><span>
</span><span id="line-270"></span><span class="hs-comment">-- * dot_i8_i8_i32</span><span>
</span><span id="line-271"></span><span class="hs-comment">-- $dot_i8_i8_i32</span><span>
</span><span id="line-272"></span><span class="hs-comment">-- </span><span>
</span><span id="line-273"></span><span>
</span><span id="line-274"></span><span class="hs-comment">-- * dot</span><span>
</span><span id="line-275"></span><span class="hs-comment">-- $dot</span><span>
</span><span id="line-276"></span><span class="hs-comment">-- </span><span>
</span><span id="line-277"></span><span class="hs-comment">-- Numeric casting is performed on the operands to the inner multiply, promoting</span><span>
</span><span id="line-278"></span><span class="hs-comment">-- them to the same data type as the accumulator/output.</span><span>
</span><span id="line-279"></span><span class="hs-comment">--       </span><span>
</span><span id="line-280"></span><span>
</span><span id="line-281"></span><span class="hs-comment">-- * fill</span><span>
</span><span id="line-282"></span><span class="hs-comment">-- $fill</span><span>
</span><span id="line-283"></span><span class="hs-comment">-- </span><span>
</span><span id="line-284"></span><span>
</span><span id="line-285"></span><span class="hs-comment">-- * fill_rng_2d</span><span>
</span><span id="line-286"></span><span class="hs-comment">-- $fill_rng_2d</span><span>
</span><span id="line-287"></span><span class="hs-comment">-- </span><span>
</span><span id="line-288"></span><span class="hs-comment">-- The operation generations pseudo random numbers using a linear congruential</span><span>
</span><span id="line-289"></span><span class="hs-comment">-- generator. It provides no guarantees regarding the distribution of the</span><span>
</span><span id="line-290"></span><span class="hs-comment">-- generated random numbers. Instead of generating the random numbers</span><span>
</span><span id="line-291"></span><span class="hs-comment">-- sequentially, it instantiates one random number generator per data element</span><span>
</span><span id="line-292"></span><span class="hs-comment">-- and runs them in parallel. The seed operand and the indices of the data</span><span>
</span><span id="line-293"></span><span class="hs-comment">-- element seed the random number generation. The min and max operands limit</span><span>
</span><span id="line-294"></span><span class="hs-comment">-- the range of the generated random numbers.</span><span>
</span><span id="line-295"></span><span class="hs-comment">--       </span><span>
</span><span id="line-296"></span><span>
</span><span id="line-297"></span><span class="hs-comment">-- * generic</span><span>
</span><span id="line-298"></span><span class="hs-comment">-- $generic</span><span>
</span><span id="line-299"></span><span class="hs-comment">-- </span><span>
</span><span id="line-300"></span><span class="hs-comment">-- Generic Linalg op form where the key properties of the computation are</span><span>
</span><span id="line-301"></span><span class="hs-comment">-- specified as attributes. In pretty form, a @linalg.generic@ op is written</span><span>
</span><span id="line-302"></span><span class="hs-comment">-- as:</span><span>
</span><span id="line-303"></span><span class="hs-comment">-- </span><span>
</span><span id="line-304"></span><span class="hs-comment">--   @</span><span>
</span><span id="line-305"></span><span class="hs-comment">--   linalg.generic \#trait_attribute</span><span>
</span><span id="line-306"></span><span class="hs-comment">--       ins(%A, %B : memref\&lt;?x?xf32, stride_specification&gt;,</span><span>
</span><span id="line-307"></span><span class="hs-comment">--                    memref\&lt;?x?xf32, stride_specification&gt;)</span><span>
</span><span id="line-308"></span><span class="hs-comment">--       outs(%C : memref\&lt;?x?xf32, stride_specification&gt;)</span><span>
</span><span id="line-309"></span><span class="hs-comment">--       attrs = {other-optional-attributes}</span><span>
</span><span id="line-310"></span><span class="hs-comment">--       {region}</span><span>
</span><span id="line-311"></span><span class="hs-comment">--   @</span><span>
</span><span id="line-312"></span><span class="hs-comment">-- </span><span>
</span><span id="line-313"></span><span class="hs-comment">-- Where \#trait_attributes is an alias of a dictionary attribute containing:</span><span>
</span><span id="line-314"></span><span class="hs-comment">--   - doc [optional]: a documentation string</span><span>
</span><span id="line-315"></span><span class="hs-comment">--   - indexing_maps: a list of AffineMapAttr, one AffineMapAttr per each input</span><span>
</span><span id="line-316"></span><span class="hs-comment">--     and output view. Such AffineMapAttr specifies the mapping between the</span><span>
</span><span id="line-317"></span><span class="hs-comment">--     loops and the indexing within each view.</span><span>
</span><span id="line-318"></span><span class="hs-comment">--   - library_call [optional]: a StringAttr containing the name of an</span><span>
</span><span id="line-319"></span><span class="hs-comment">--     external library function that the linalg.generic operation maps to.</span><span>
</span><span id="line-320"></span><span class="hs-comment">--     The external library is assumed to be dynamically linked and no strong</span><span>
</span><span id="line-321"></span><span class="hs-comment">--     compile-time guarantees are provided. In the absence of such a library</span><span>
</span><span id="line-322"></span><span class="hs-comment">--     call, linalg.generic will always lower to loops.</span><span>
</span><span id="line-323"></span><span class="hs-comment">--   - iterator_types: an ArrayAttr specifying the type of the enclosing loops.</span><span>
</span><span id="line-324"></span><span class="hs-comment">--     Each element of the list represents and iterator of one of the following</span><span>
</span><span id="line-325"></span><span class="hs-comment">--     types:</span><span>
</span><span id="line-326"></span><span class="hs-comment">--       parallel, reduction, window</span><span>
</span><span id="line-327"></span><span class="hs-comment">-- </span><span>
</span><span id="line-328"></span><span class="hs-comment">-- Example:</span><span>
</span><span id="line-329"></span><span class="hs-comment">-- Defining a \#matmul_trait attribute in MLIR can be done as follows:</span><span>
</span><span id="line-330"></span><span class="hs-comment">--   @</span><span>
</span><span id="line-331"></span><span class="hs-comment">--   \#matmul_accesses = [</span><span>
</span><span id="line-332"></span><span class="hs-comment">--     (m, n, k) -&gt; (m, k),</span><span>
</span><span id="line-333"></span><span class="hs-comment">--     (m, n, k) -&gt; (k, n),</span><span>
</span><span id="line-334"></span><span class="hs-comment">--     (m, n, k) -&gt; (m, n)</span><span>
</span><span id="line-335"></span><span class="hs-comment">--   ]</span><span>
</span><span id="line-336"></span><span class="hs-comment">--   \#matmul_trait = {</span><span>
</span><span id="line-337"></span><span class="hs-comment">--     doc = \&quot;C(m, n) += A(m, k) * B(k, n)\&quot;,</span><span>
</span><span id="line-338"></span><span class="hs-comment">--     indexing_maps = \#matmul_accesses,</span><span>
</span><span id="line-339"></span><span class="hs-comment">--     library_call = \&quot;linalg_matmul\&quot;,</span><span>
</span><span id="line-340"></span><span class="hs-comment">--     iterator_types = [\&quot;parallel\&quot;, \&quot;parallel\&quot;, \&quot;reduction\&quot;]</span><span>
</span><span id="line-341"></span><span class="hs-comment">--   }</span><span>
</span><span id="line-342"></span><span class="hs-comment">--   @</span><span>
</span><span id="line-343"></span><span class="hs-comment">-- </span><span>
</span><span id="line-344"></span><span class="hs-comment">-- And can be reused in multiple places as:</span><span>
</span><span id="line-345"></span><span class="hs-comment">--   @</span><span>
</span><span id="line-346"></span><span class="hs-comment">--   linalg.generic \#matmul_trait</span><span>
</span><span id="line-347"></span><span class="hs-comment">--     ins(%A, %B : memref\&lt;?x?xf32, stride_specification&gt;,</span><span>
</span><span id="line-348"></span><span class="hs-comment">--                  memref\&lt;?x?xf32, stride_specification&gt;)</span><span>
</span><span id="line-349"></span><span class="hs-comment">--     outs(%C : memref\&lt;?x?xf32, stride_specification&gt;)</span><span>
</span><span id="line-350"></span><span class="hs-comment">--     {other-optional-attributes} {</span><span>
</span><span id="line-351"></span><span class="hs-comment">--     ^bb0(%a: f32, %b: f32, %c: f32) :</span><span>
</span><span id="line-352"></span><span class="hs-comment">--       %d = mulf %a, %b: f32</span><span>
</span><span id="line-353"></span><span class="hs-comment">--       %e = addf %c, %d: f32</span><span>
</span><span id="line-354"></span><span class="hs-comment">--       linalg.yield %e : f32</span><span>
</span><span id="line-355"></span><span class="hs-comment">--   }</span><span>
</span><span id="line-356"></span><span class="hs-comment">--   @</span><span>
</span><span id="line-357"></span><span class="hs-comment">-- </span><span>
</span><span id="line-358"></span><span class="hs-comment">-- This may lower to either:</span><span>
</span><span id="line-359"></span><span class="hs-comment">--   @</span><span>
</span><span id="line-360"></span><span class="hs-comment">--   call \@linalg_matmul(%A, %B, %C) :</span><span>
</span><span id="line-361"></span><span class="hs-comment">--     (memref\&lt;?x?xf32, stride_specification&gt;,</span><span>
</span><span id="line-362"></span><span class="hs-comment">--      memref\&lt;?x?xf32, stride_specification&gt;,</span><span>
</span><span id="line-363"></span><span class="hs-comment">--      memref\&lt;?x?xf32, stride_specification&gt;)</span><span>
</span><span id="line-364"></span><span class="hs-comment">--     -&gt; ()</span><span>
</span><span id="line-365"></span><span class="hs-comment">--   @</span><span>
</span><span id="line-366"></span><span class="hs-comment">-- </span><span>
</span><span id="line-367"></span><span class="hs-comment">-- or IR resembling:</span><span>
</span><span id="line-368"></span><span class="hs-comment">-- @</span><span>
</span><span id="line-369"></span><span class="hs-comment">-- scf.for %m = %c0 to %M step %c1 {</span><span>
</span><span id="line-370"></span><span class="hs-comment">--   scf.for %n = %c0 to %N step %c1 {</span><span>
</span><span id="line-371"></span><span class="hs-comment">--     scf.for %k = %c0 to %K step %c1 {</span><span>
</span><span id="line-372"></span><span class="hs-comment">--       %a = load %A[%m, %k] : memref\&lt;?x?xf32, stride_specification&gt;</span><span>
</span><span id="line-373"></span><span class="hs-comment">--       %b = load %B[%k, %n] : memref\&lt;?x?xf32, stride_specification&gt;</span><span>
</span><span id="line-374"></span><span class="hs-comment">--       %c = load %C[%m, %n] : memref\&lt;?x?xf32, stride_specification&gt;</span><span>
</span><span id="line-375"></span><span class="hs-comment">--       %d = mulf %a, %b: f32</span><span>
</span><span id="line-376"></span><span class="hs-comment">--       %e = addf %c, %d: f32</span><span>
</span><span id="line-377"></span><span class="hs-comment">--       store %e, %C[%m, %n] : memref\&lt;?x?x?xf32, stride_specification&gt;</span><span>
</span><span id="line-378"></span><span class="hs-comment">--     }</span><span>
</span><span id="line-379"></span><span class="hs-comment">--   }</span><span>
</span><span id="line-380"></span><span class="hs-comment">-- }</span><span>
</span><span id="line-381"></span><span class="hs-comment">-- @</span><span>
</span><span id="line-382"></span><span class="hs-comment">-- </span><span>
</span><span id="line-383"></span><span class="hs-comment">-- To allow progressive lowering from the value world (a.k.a tensor values) to</span><span>
</span><span id="line-384"></span><span class="hs-comment">-- the buffer world (a.k.a memref values), a @linalg.generic@ op allows mixing</span><span>
</span><span id="line-385"></span><span class="hs-comment">-- tensors and buffers operands and tensor results.</span><span>
</span><span id="line-386"></span><span class="hs-comment">-- </span><span>
</span><span id="line-387"></span><span class="hs-comment">-- @</span><span>
</span><span id="line-388"></span><span class="hs-comment">-- %C = linalg.generic \#trait_attribute</span><span>
</span><span id="line-389"></span><span class="hs-comment">--   ins(%A, %B : tensor\&lt;?x?xf32&gt;, memref\&lt;?x?xf32, stride_specification&gt;)</span><span>
</span><span id="line-390"></span><span class="hs-comment">--   outs(%C : tensor\&lt;?x?xf32&gt;)</span><span>
</span><span id="line-391"></span><span class="hs-comment">--   {other-optional-attributes}</span><span>
</span><span id="line-392"></span><span class="hs-comment">--   {region}</span><span>
</span><span id="line-393"></span><span class="hs-comment">--   -&gt; (tensor\&lt;?x?xf32&gt;)</span><span>
</span><span id="line-394"></span><span class="hs-comment">-- @</span><span>
</span><span id="line-395"></span><span class="hs-comment">--   </span><span>
</span><span id="line-396"></span><span>
</span><span id="line-397"></span><span class="hs-keyword">pattern</span><span> </span><span class="annot"><a href="MLIR.AST.Dialect.Generated.LinalgStructured.html#InternalGenericOpAttributes"><span class="hs-identifier hs-type">InternalGenericOpAttributes</span></a></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><a href="MLIR.AST.Dialect.Affine.html#Map"><span class="hs-identifier hs-type">Affine.Map</span></a></span><span class="hs-special">]</span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">[</span><span class="annot"><a href="MLIR.AST.html#Attribute"><span class="hs-identifier hs-type">Attribute</span></a></span><span class="hs-special">]</span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="hs-identifier hs-type">BS.ByteString</span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="hs-identifier hs-type">BS.ByteString</span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="MLIR.AST.html#NamedAttributes"><span class="hs-identifier hs-type">NamedAttributes</span></a></span><span>
</span><span id="line-398"></span><span class="hs-keyword">pattern</span><span> </span><span id="%24bInternalGenericOpAttributes"><span id="%24mInternalGenericOpAttributes"><span id="InternalGenericOpAttributes"><span class="annot"><span class="annottext">$bInternalGenericOpAttributes :: [Map] -&gt; [Attribute] -&gt; Name -&gt; Name -&gt; NamedAttributes
$mInternalGenericOpAttributes :: forall r.
NamedAttributes
-&gt; ([Map] -&gt; [Attribute] -&gt; Name -&gt; Name -&gt; r) -&gt; (Void# -&gt; r) -&gt; r
</span><a href="MLIR.AST.Dialect.Generated.LinalgStructured.html#%24bInternalGenericOpAttributes"><span class="hs-identifier hs-var hs-var hs-var hs-var">InternalGenericOpAttributes</span></a></span></span></span></span><span> </span><span class="annot"><a href="#local-6989586621679296744"><span class="hs-identifier hs-type">indexing_maps</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679296743"><span class="hs-identifier hs-type">iterator_types</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679296742"><span class="hs-identifier hs-type">doc</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679296741"><span class="hs-identifier hs-type">library_call</span></a></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="hs-special">(</span><span class="hs-special">(</span><span class="hs-glyph">\</span><span id="local-6989586621679296740"><span class="annot"><a href="#local-6989586621679296740"><span class="hs-identifier hs-var">m</span></a></span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">M.lookup</span></span><span> </span><span class="annot"><span class="hs-string">&quot;indexing_maps&quot;</span></span><span> </span><span class="annot"><a href="#local-6989586621679296740"><span class="hs-identifier hs-type">m</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">M.lookup</span></span><span> </span><span class="annot"><span class="hs-string">&quot;iterator_types&quot;</span></span><span> </span><span class="annot"><a href="#local-6989586621679296740"><span class="hs-identifier hs-type">m</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">M.lookup</span></span><span> </span><span class="annot"><span class="hs-string">&quot;doc&quot;</span></span><span> </span><span class="annot"><a href="#local-6989586621679296740"><span class="hs-identifier hs-type">m</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">M.lookup</span></span><span> </span><span class="annot"><span class="hs-string">&quot;library_call&quot;</span></span><span> </span><span class="annot"><a href="#local-6989586621679296740"><span class="hs-identifier hs-type">m</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">Just</span></span><span> </span><span class="hs-special">(</span><span class="hs-special">(</span><span class="annot"><a href="MLIR.AST.PatternUtil.html#AffineMapArrayAttr"><span class="hs-identifier hs-type">AffineMapArrayAttr</span></a></span><span> </span><span id="local-6989586621679296744"><span class="annot"><a href="#local-6989586621679296744"><span class="hs-identifier hs-var">indexing_maps</span></a></span></span><span class="hs-special">)</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Just</span></span><span> </span><span class="hs-special">(</span><span class="hs-special">(</span><span class="annot"><a href="MLIR.AST.html#ArrayAttr"><span class="hs-identifier hs-type">ArrayAttr</span></a></span><span> </span><span id="local-6989586621679296743"><span class="annot"><a href="#local-6989586621679296743"><span class="hs-identifier hs-var">iterator_types</span></a></span></span><span class="hs-special">)</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Just</span></span><span> </span><span class="hs-special">(</span><span class="hs-special">(</span><span class="annot"><a href="MLIR.AST.html#StringAttr"><span class="hs-identifier hs-type">StringAttr</span></a></span><span> </span><span id="local-6989586621679296742"><span class="annot"><a href="#local-6989586621679296742"><span class="hs-identifier hs-var">doc</span></a></span></span><span class="hs-special">)</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Just</span></span><span> </span><span class="hs-special">(</span><span class="hs-special">(</span><span class="annot"><a href="MLIR.AST.html#StringAttr"><span class="hs-identifier hs-type">StringAttr</span></a></span><span> </span><span id="local-6989586621679296741"><span class="annot"><a href="#local-6989586621679296741"><span class="hs-identifier hs-var">library_call</span></a></span></span><span class="hs-special">)</span><span class="hs-special">)</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-399"></span><span>  </span><span class="hs-keyword">where</span><span> </span><span class="annot"><a href="MLIR.AST.Dialect.Generated.LinalgStructured.html#InternalGenericOpAttributes"><span class="hs-identifier hs-var">InternalGenericOpAttributes</span></a></span><span> </span><span id="local-6989586621679296736"><span class="annot"><span class="annottext">[Map]
</span><a href="#local-6989586621679296736"><span class="hs-identifier hs-var">indexing_maps</span></a></span></span><span> </span><span id="local-6989586621679296735"><span class="annot"><span class="annottext">[Attribute]
</span><a href="#local-6989586621679296735"><span class="hs-identifier hs-var">iterator_types</span></a></span></span><span> </span><span id="local-6989586621679296734"><span class="annot"><span class="annottext">Name
</span><a href="#local-6989586621679296734"><span class="hs-identifier hs-var">doc</span></a></span></span><span> </span><span id="local-6989586621679296733"><span class="annot"><span class="annottext">Name
</span><a href="#local-6989586621679296733"><span class="hs-identifier hs-var">library_call</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">[(Name, Attribute)] -&gt; NamedAttributes
forall k a. Ord k =&gt; [(k, a)] -&gt; Map k a
</span><span class="hs-identifier hs-var">M.fromList</span></span><span> </span><span class="hs-special">[</span><span class="hs-special">(</span><span class="annot"><span class="annottext">Name
</span><span class="hs-string">&quot;indexing_maps&quot;</span></span><span class="hs-special">,</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">[Map] -&gt; Attribute
</span><a href="MLIR.AST.PatternUtil.html#AffineMapArrayAttr"><span class="hs-identifier hs-var">AffineMapArrayAttr</span></a></span><span> </span><span class="annot"><span class="annottext">[Map]
</span><a href="#local-6989586621679296736"><span class="hs-identifier hs-var">indexing_maps</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Name
</span><span class="hs-string">&quot;iterator_types&quot;</span></span><span class="hs-special">,</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">[Attribute] -&gt; Attribute
</span><a href="MLIR.AST.html#ArrayAttr"><span class="hs-identifier hs-var">ArrayAttr</span></a></span><span> </span><span class="annot"><span class="annottext">[Attribute]
</span><a href="#local-6989586621679296735"><span class="hs-identifier hs-var">iterator_types</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Name
</span><span class="hs-string">&quot;doc&quot;</span></span><span class="hs-special">,</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Name -&gt; Attribute
</span><a href="MLIR.AST.html#StringAttr"><span class="hs-identifier hs-var">StringAttr</span></a></span><span> </span><span class="annot"><span class="annottext">Name
</span><a href="#local-6989586621679296734"><span class="hs-identifier hs-var">doc</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Name
</span><span class="hs-string">&quot;library_call&quot;</span></span><span class="hs-special">,</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Name -&gt; Attribute
</span><a href="MLIR.AST.html#StringAttr"><span class="hs-identifier hs-var">StringAttr</span></a></span><span> </span><span class="annot"><span class="annottext">Name
</span><a href="#local-6989586621679296733"><span class="hs-identifier hs-var">library_call</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span class="hs-special">]</span><span>
</span><span id="line-400"></span><span>
</span><span id="line-401"></span><span class="hs-comment">-- * matmul_column_major</span><span>
</span><span id="line-402"></span><span class="hs-comment">-- $matmul_column_major</span><span>
</span><span id="line-403"></span><span class="hs-comment">-- </span><span>
</span><span id="line-404"></span><span>
</span><span id="line-405"></span><span class="hs-comment">-- * matmul_i16_i16_i32</span><span>
</span><span id="line-406"></span><span class="hs-comment">-- $matmul_i16_i16_i32</span><span>
</span><span id="line-407"></span><span class="hs-comment">-- </span><span>
</span><span id="line-408"></span><span>
</span><span id="line-409"></span><span class="hs-comment">-- * matmul_i32_i32_i32</span><span>
</span><span id="line-410"></span><span class="hs-comment">-- $matmul_i32_i32_i32</span><span>
</span><span id="line-411"></span><span class="hs-comment">-- </span><span>
</span><span id="line-412"></span><span>
</span><span id="line-413"></span><span class="hs-comment">-- * matmul_i8_i8_i32</span><span>
</span><span id="line-414"></span><span class="hs-comment">-- $matmul_i8_i8_i32</span><span>
</span><span id="line-415"></span><span class="hs-comment">-- </span><span>
</span><span id="line-416"></span><span>
</span><span id="line-417"></span><span class="hs-comment">-- * matmul</span><span>
</span><span id="line-418"></span><span class="hs-comment">-- $matmul</span><span>
</span><span id="line-419"></span><span class="hs-comment">-- </span><span>
</span><span id="line-420"></span><span class="hs-comment">-- Numeric casting is performed on the operands to the inner multiply, promoting</span><span>
</span><span id="line-421"></span><span class="hs-comment">-- them to the same data type as the accumulator/output.</span><span>
</span><span id="line-422"></span><span class="hs-comment">--       </span><span>
</span><span id="line-423"></span><span>
</span><span id="line-424"></span><span class="hs-comment">-- * matvec_i16_i16_i32</span><span>
</span><span id="line-425"></span><span class="hs-comment">-- $matvec_i16_i16_i32</span><span>
</span><span id="line-426"></span><span class="hs-comment">-- </span><span>
</span><span id="line-427"></span><span>
</span><span id="line-428"></span><span class="hs-comment">-- * matvec_i32_i32_i32</span><span>
</span><span id="line-429"></span><span class="hs-comment">-- $matvec_i32_i32_i32</span><span>
</span><span id="line-430"></span><span class="hs-comment">-- </span><span>
</span><span id="line-431"></span><span>
</span><span id="line-432"></span><span class="hs-comment">-- * matvec_i8_i8_i32</span><span>
</span><span id="line-433"></span><span class="hs-comment">-- $matvec_i8_i8_i32</span><span>
</span><span id="line-434"></span><span class="hs-comment">-- </span><span>
</span><span id="line-435"></span><span>
</span><span id="line-436"></span><span class="hs-comment">-- * matvec</span><span>
</span><span id="line-437"></span><span class="hs-comment">-- $matvec</span><span>
</span><span id="line-438"></span><span class="hs-comment">-- </span><span>
</span><span id="line-439"></span><span class="hs-comment">-- Numeric casting is performed on the operands to the inner multiply, promoting</span><span>
</span><span id="line-440"></span><span class="hs-comment">-- them to the same data type as the accumulator/output.</span><span>
</span><span id="line-441"></span><span class="hs-comment">--       </span><span>
</span><span id="line-442"></span><span>
</span><span id="line-443"></span><span class="hs-comment">-- * pooling_max</span><span>
</span><span id="line-444"></span><span class="hs-comment">-- $pooling_max</span><span>
</span><span id="line-445"></span><span class="hs-comment">-- </span><span>
</span><span id="line-446"></span><span class="hs-comment">-- Takes max op as pooling operation, i.e., it samples the maximum value in the</span><span>
</span><span id="line-447"></span><span class="hs-comment">-- window.</span><span>
</span><span id="line-448"></span><span class="hs-comment">--   </span><span>
</span><span id="line-449"></span><span>
</span><span id="line-450"></span><span class="hs-comment">-- * pooling_min</span><span>
</span><span id="line-451"></span><span class="hs-comment">-- $pooling_min</span><span>
</span><span id="line-452"></span><span class="hs-comment">-- </span><span>
</span><span id="line-453"></span><span class="hs-comment">-- Takes min op as pooling operation, i.e., it samples the minimum value in the</span><span>
</span><span id="line-454"></span><span class="hs-comment">-- window.</span><span>
</span><span id="line-455"></span><span class="hs-comment">--   </span><span>
</span><span id="line-456"></span><span>
</span><span id="line-457"></span><span class="hs-comment">-- * pooling_nhwc_max</span><span>
</span><span id="line-458"></span><span class="hs-comment">-- $pooling_nhwc_max</span><span>
</span><span id="line-459"></span><span class="hs-comment">-- </span><span>
</span><span id="line-460"></span><span>
</span><span id="line-461"></span><span class="hs-comment">-- * pooling_nhwc_i16_max</span><span>
</span><span id="line-462"></span><span class="hs-comment">-- $pooling_nhwc_i16_max</span><span>
</span><span id="line-463"></span><span class="hs-comment">-- </span><span>
</span><span id="line-464"></span><span>
</span><span id="line-465"></span><span class="hs-comment">-- * pooling_nhwc_i32_max</span><span>
</span><span id="line-466"></span><span class="hs-comment">-- $pooling_nhwc_i32_max</span><span>
</span><span id="line-467"></span><span class="hs-comment">-- </span><span>
</span><span id="line-468"></span><span>
</span><span id="line-469"></span><span class="hs-comment">-- * pooling_nhwc_i8_max</span><span>
</span><span id="line-470"></span><span class="hs-comment">-- $pooling_nhwc_i8_max</span><span>
</span><span id="line-471"></span><span class="hs-comment">-- </span><span>
</span><span id="line-472"></span><span>
</span><span id="line-473"></span><span class="hs-comment">-- * pooling_nhwc_min</span><span>
</span><span id="line-474"></span><span class="hs-comment">-- $pooling_nhwc_min</span><span>
</span><span id="line-475"></span><span class="hs-comment">-- </span><span>
</span><span id="line-476"></span><span>
</span><span id="line-477"></span><span class="hs-comment">-- * pooling_nhwc_sum</span><span>
</span><span id="line-478"></span><span class="hs-comment">-- $pooling_nhwc_sum</span><span>
</span><span id="line-479"></span><span class="hs-comment">-- </span><span>
</span><span id="line-480"></span><span>
</span><span id="line-481"></span><span class="hs-comment">-- * pooling_sum</span><span>
</span><span id="line-482"></span><span class="hs-comment">-- $pooling_sum</span><span>
</span><span id="line-483"></span><span class="hs-comment">-- </span><span>
</span><span id="line-484"></span><span class="hs-comment">-- Takes add op as pooling operation, i.e., it accumulates the values in the</span><span>
</span><span id="line-485"></span><span class="hs-comment">-- window.</span><span>
</span><span id="line-486"></span><span class="hs-comment">--   </span><span>
</span><span id="line-487"></span><span>
</span><span id="line-488"></span><span class="hs-comment">-- * vecmat_i16_i16_i32</span><span>
</span><span id="line-489"></span><span class="hs-comment">-- $vecmat_i16_i16_i32</span><span>
</span><span id="line-490"></span><span class="hs-comment">-- </span><span>
</span><span id="line-491"></span><span>
</span><span id="line-492"></span><span class="hs-comment">-- * vecmat_i32_i32_i32</span><span>
</span><span id="line-493"></span><span class="hs-comment">-- $vecmat_i32_i32_i32</span><span>
</span><span id="line-494"></span><span class="hs-comment">-- </span><span>
</span><span id="line-495"></span><span>
</span><span id="line-496"></span><span class="hs-comment">-- * vecmat_i8_i8_i32</span><span>
</span><span id="line-497"></span><span class="hs-comment">-- $vecmat_i8_i8_i32</span><span>
</span><span id="line-498"></span><span class="hs-comment">-- </span><span>
</span><span id="line-499"></span><span>
</span><span id="line-500"></span><span class="hs-comment">-- * vecmat</span><span>
</span><span id="line-501"></span><span class="hs-comment">-- $vecmat</span><span>
</span><span id="line-502"></span><span class="hs-comment">-- </span><span>
</span><span id="line-503"></span><span class="hs-comment">-- Numeric casting is performed on the operands to the inner multiply, promoting</span><span>
</span><span id="line-504"></span><span class="hs-comment">-- them to the same data type as the accumulator/output.</span><span>
</span><span id="line-505"></span><span class="hs-comment">--       </span><span>
</span><span id="line-506"></span></pre></body></html>